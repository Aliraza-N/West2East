{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "multiple-seminar",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ipykernel/__main__.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ipykernel/__main__.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ipykernel/__main__.py:32: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ipykernel/__main__.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ipykernel/__main__.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ipykernel/__main__.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ipykernel/__main__.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ipykernel/__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ipykernel/__main__.py:38: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ipykernel/__main__.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('tsv.csv')\n",
    "\n",
    "df['date_of_infraction']= pd.to_datetime(df['date_of_infraction'])\n",
    "\n",
    "df['Count Date'] = df['Count Date'].str.replace('*', '').str.replace(',', '')\n",
    "\n",
    "df['Latitude'] = df['Latitude'].str.replace('*', '').str.replace(',', '')\n",
    "\n",
    "df['Longitude'] = df['Longitude'].str.replace('*', '').str.replace(',', '')\n",
    "\n",
    "df['Longitude'] = df['Longitude'].str.replace('*', '').str.replace(',', '')\n",
    "\n",
    "df['8 Peak Hr Vehicle Volume'] = df['8 Peak Hr Vehicle Volume'].str.replace('*', '').str.replace(',', '')\n",
    "df['8 Peak Hr Pedestrian Volume'] = df['8 Peak Hr Pedestrian Volume'].str.replace('*', '').str.replace(',', '')\n",
    "df['Activation Date'] = df['Activation Date'].str.replace('*', '').str.replace(',', '')\n",
    "df['TCS '] = df['TCS '].str.replace('*', '').str.replace(',', '')\n",
    "\n",
    "df['Count Date']= pd.to_datetime(df['Count Date'])\n",
    "\n",
    "df['Activation Date']= pd.to_datetime(df['Activation Date'])\n",
    "\n",
    "df\n",
    "\n",
    "df1 = df[['date_of_infraction','set_fine_amount','time_of_infraction','location2','Latitude','Longitude','Count Date','8 Peak Hr Vehicle Volume','8 Peak Hr Pedestrian Volume']]\n",
    "\n",
    "df1\n",
    "\n",
    "df1['date_of_infraction_year'] = df1['date_of_infraction'].dt.year\n",
    "df1['date_of_infraction_month'] = df1['date_of_infraction'].dt.month\n",
    "df1['date_of_infraction_week'] = df1['date_of_infraction'].dt.week\n",
    "df1['date_of_infraction_day'] = df1['date_of_infraction'].dt.day\n",
    "df1['date_of_infraction_dayofweek'] = df1['date_of_infraction'].dt.dayofweek\n",
    "\n",
    "df1['Count Date_year'] = df1['Count Date'].dt.year\n",
    "df1['Count Date_month'] = df1['Count Date'].dt.month\n",
    "df1['Count Date_week'] = df1['Count Date'].dt.week\n",
    "df1['Count Date_day'] = df1['Count Date'].dt.day\n",
    "df1['Count Date_dayofweek'] = df1['Count Date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "removable-separation",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 15.1 GiB for an array with shape (127353, 127353) and data type uint8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-392e5ee82148>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mone_hot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'location2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Drop column as it is now encoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'location2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Join the encoded df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0mdrop_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_first\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m         )\n\u001b[1;32m    910\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36m_get_dummies_1d\u001b[0;34m(data, prefix, prefix_sep, dummy_na, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m         \u001b[0mdummy_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdummy_na\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/numpy/lib/twodim_base.py\u001b[0m in \u001b[0;36meye\u001b[0;34m(N, M, k, dtype, order)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mM\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 15.1 GiB for an array with shape (127353, 127353) and data type uint8"
     ]
    }
   ],
   "source": [
    "one_hot=pd.get_dummies(df1['location2'])\n",
    "# Drop column as it is now encoded\n",
    "df1 = df1.drop('location2',axis = 1)\n",
    "# Join the encoded df\n",
    "df1 = df1.join(one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "novel-jungle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>set_fine_amount</th>\n",
       "      <th>time_of_infraction</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>8 Peak Hr Vehicle Volume</th>\n",
       "      <th>8 Peak Hr Pedestrian Volume</th>\n",
       "      <th>date_of_infraction_year</th>\n",
       "      <th>date_of_infraction_month</th>\n",
       "      <th>date_of_infraction_week</th>\n",
       "      <th>date_of_infraction_day</th>\n",
       "      <th>date_of_infraction_dayofweek</th>\n",
       "      <th>Count Date_year</th>\n",
       "      <th>Count Date_month</th>\n",
       "      <th>Count Date_week</th>\n",
       "      <th>Count Date_day</th>\n",
       "      <th>Count Date_dayofweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.818186976</td>\n",
       "      <td>-79.173580043</td>\n",
       "      <td>1982</td>\n",
       "      <td>16</td>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>43.818186976</td>\n",
       "      <td>-79.173580043</td>\n",
       "      <td>1982</td>\n",
       "      <td>16</td>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>43.818186976</td>\n",
       "      <td>-79.173580043</td>\n",
       "      <td>1982</td>\n",
       "      <td>16</td>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>43.73338</td>\n",
       "      <td>-79.24867</td>\n",
       "      <td>10664</td>\n",
       "      <td>253</td>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>43.7905795</td>\n",
       "      <td>-79.2699662</td>\n",
       "      <td>13883</td>\n",
       "      <td>72</td>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955192</th>\n",
       "      <td>30</td>\n",
       "      <td>1342.0</td>\n",
       "      <td>43.81818698</td>\n",
       "      <td>-79.173580043</td>\n",
       "      <td>1982</td>\n",
       "      <td>16</td>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955193</th>\n",
       "      <td>100</td>\n",
       "      <td>1342.0</td>\n",
       "      <td>43.63661608</td>\n",
       "      <td>-79.396928931</td>\n",
       "      <td>5781</td>\n",
       "      <td>1156</td>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955194</th>\n",
       "      <td>50</td>\n",
       "      <td>1342.0</td>\n",
       "      <td>43.81818698</td>\n",
       "      <td>-79.173580043</td>\n",
       "      <td>1982</td>\n",
       "      <td>16</td>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955195</th>\n",
       "      <td>150</td>\n",
       "      <td>1342.0</td>\n",
       "      <td>43.81818698</td>\n",
       "      <td>-79.173580043</td>\n",
       "      <td>1982</td>\n",
       "      <td>16</td>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955196</th>\n",
       "      <td>100</td>\n",
       "      <td>1342.0</td>\n",
       "      <td>43.81818698</td>\n",
       "      <td>-79.173580043</td>\n",
       "      <td>1982</td>\n",
       "      <td>16</td>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>955197 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        set_fine_amount  time_of_infraction      Latitude      Longitude  \\\n",
       "0                    30                 1.0  43.818186976  -79.173580043   \n",
       "1                    30                 2.0  43.818186976  -79.173580043   \n",
       "2                    30                 2.0  43.818186976  -79.173580043   \n",
       "3                    30                 4.0      43.73338      -79.24867   \n",
       "4                    30                 4.0    43.7905795    -79.2699662   \n",
       "...                 ...                 ...           ...            ...   \n",
       "955192               30              1342.0   43.81818698  -79.173580043   \n",
       "955193              100              1342.0   43.63661608  -79.396928931   \n",
       "955194               50              1342.0   43.81818698  -79.173580043   \n",
       "955195              150              1342.0   43.81818698  -79.173580043   \n",
       "955196              100              1342.0   43.81818698  -79.173580043   \n",
       "\n",
       "       8 Peak Hr Vehicle Volume 8 Peak Hr Pedestrian Volume  \\\n",
       "0                          1982                          16   \n",
       "1                          1982                          16   \n",
       "2                          1982                          16   \n",
       "3                         10664                         253   \n",
       "4                         13883                          72   \n",
       "...                         ...                         ...   \n",
       "955192                     1982                          16   \n",
       "955193                     5781                        1156   \n",
       "955194                     1982                          16   \n",
       "955195                     1982                          16   \n",
       "955196                     1982                          16   \n",
       "\n",
       "        date_of_infraction_year  date_of_infraction_month  \\\n",
       "0                          1970                         1   \n",
       "1                          1970                         1   \n",
       "2                          1970                         1   \n",
       "3                          1970                         1   \n",
       "4                          1970                         1   \n",
       "...                         ...                       ...   \n",
       "955192                     1970                         1   \n",
       "955193                     1970                         1   \n",
       "955194                     1970                         1   \n",
       "955195                     1970                         1   \n",
       "955196                     1970                         1   \n",
       "\n",
       "        date_of_infraction_week  date_of_infraction_day  \\\n",
       "0                             1                       1   \n",
       "1                             1                       1   \n",
       "2                             1                       1   \n",
       "3                             1                       1   \n",
       "4                             1                       1   \n",
       "...                         ...                     ...   \n",
       "955192                        1                       1   \n",
       "955193                        1                       1   \n",
       "955194                        1                       1   \n",
       "955195                        1                       1   \n",
       "955196                        1                       1   \n",
       "\n",
       "        date_of_infraction_dayofweek  Count Date_year  Count Date_month  \\\n",
       "0                                  3             2009                 7   \n",
       "1                                  3             2009                 7   \n",
       "2                                  3             2009                 7   \n",
       "3                                  3             2016                 5   \n",
       "4                                  3             2016                12   \n",
       "...                              ...              ...               ...   \n",
       "955192                             3             2009                 7   \n",
       "955193                             3             2012                 2   \n",
       "955194                             3             2009                 7   \n",
       "955195                             3             2009                 7   \n",
       "955196                             3             2009                 7   \n",
       "\n",
       "        Count Date_week  Count Date_day  Count Date_dayofweek  \n",
       "0                    30              26                     6  \n",
       "1                    30              26                     6  \n",
       "2                    30              26                     6  \n",
       "3                    21              26                     3  \n",
       "4                    50              15                     3  \n",
       "...                 ...             ...                   ...  \n",
       "955192               30              26                     6  \n",
       "955193                8              22                     2  \n",
       "955194               30              26                     6  \n",
       "955195               30              26                     6  \n",
       "955196               30              26                     6  \n",
       "\n",
       "[955197 rows x 16 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "elegant-heading",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop('date_of_infraction',axis = 1)\n",
    "df1 = df1.drop('Count Date',axis = 1)\n",
    "df1 = df1.drop('location2',axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "palestinian-austria",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "precise-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"8 Peak Hr Vehicle Volume\"] = df1[\"8 Peak Hr Vehicle Volume\"].astype(str).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "advance-circumstances",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"8 Peak Hr Pedestrian Volume\"] = df1[\"8 Peak Hr Pedestrian Volume\"].astype(str).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "monetary-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['hour_sin'] = np.sin(2 * np.pi * df1['time_of_infraction']/23.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "continental-chamber",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['hour_cos'] = np.cos(2 * np.pi * df1['time_of_infraction']/23.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ahead-preservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"Latitude\"] = df1.Latitude.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "british-intersection",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"Longitude\"] = df1.Latitude.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dominant-drive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(df1.values >= np.finfo(np.float64).max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "falling-world",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "convertible-following",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set_fine_amount                 False\n",
       "time_of_infraction              False\n",
       "Latitude                        False\n",
       "Longitude                       False\n",
       "8 Peak Hr Vehicle Volume        False\n",
       "8 Peak Hr Pedestrian Volume     False\n",
       "date_of_infraction_year         False\n",
       "date_of_infraction_month        False\n",
       "date_of_infraction_week         False\n",
       "date_of_infraction_day          False\n",
       "date_of_infraction_dayofweek    False\n",
       "Count Date_year                 False\n",
       "Count Date_month                False\n",
       "Count Date_week                 False\n",
       "Count Date_day                  False\n",
       "Count Date_dayofweek            False\n",
       "hour_sin                        False\n",
       "hour_cos                        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(df1).sum() > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "wrapped-bulletin",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df1.drop(columns=['8 Peak Hr Vehicle Volume','8 Peak Hr Pedestrian Volume'])\n",
    "y= df1[['8 Peak Hr Vehicle Volume','8 Peak Hr Pedestrian Volume']]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dominant-professor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.4.1-cp36-cp36m-manylinux2010_x86_64.whl (394.3 MB)\n",
      "\u001b[K     |███████████████████████▍        | 288.2 MB 111.7 MB/s eta 0:00:01     |███████████████▊                | 193.9 MB 147.1 MB/s eta 0:00:02     |█████████████████████▊          | 268.3 MB 147.1 MB/s eta 0:00:01"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 394.3 MB 124.7 MB/s eta 0:00:01\u001b[K     |████████████████████████████████| 394.3 MB 14 kB/s \n",
      "\u001b[?25hCollecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from tensorflow) (1.19.2)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 84.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard~=2.4\n",
      "  Downloading tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.6 MB 38.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from tensorflow) (3.15.3)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 813 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from tensorflow) (1.12.1)\n",
      "Collecting tensorflow-estimator<2.5.0,>=2.4.0\n",
      "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 83.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 2.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting h5py~=2.10.0\n",
      "  Downloading h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 65.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio~=1.32.0\n",
      "  Downloading grpcio-1.32.0-cp36-cp36m-manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 61.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow) (49.6.0.post20210108)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow) (2.25.1)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.27.1-py2.py3-none-any.whl (136 kB)\n",
      "\u001b[K     |████████████████████████████████| 136 kB 96.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.3-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 13.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 90.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 110.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.1-py3-none-any.whl (12 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.26.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 111.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.0)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=bd7b4a2f524024bba6be64de4c30c2b9b324ddbb49612419d225c8f4d968cc9c\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
      "Successfully built termcolor\n",
      "Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, h5py, gast, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.1.0\n",
      "    Uninstalling h5py-3.1.0:\n",
      "      Successfully uninstalled h5py-3.1.0\n",
      "Successfully installed absl-py-0.11.0 astunparse-1.6.3 cachetools-4.2.1 flatbuffers-1.12 gast-0.3.3 google-auth-1.27.1 google-auth-oauthlib-0.4.3 grpcio-1.32.0 h5py-2.10.0 keras-preprocessing-1.1.2 markdown-3.3.4 oauthlib-3.1.0 opt-einsum-3.3.0 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 tensorboard-2.4.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.4.1 tensorflow-estimator-2.4.0 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "requested-alpha",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from keras) (1.19.2)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from keras) (5.4.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from keras) (1.5.3)\n",
      "Requirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from h5py->keras) (1.15.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "manual-snapshot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=10, kernel_initializer='he_uniform', activation='relu'))\n",
    "model.add(Dense(3))\n",
    "model.compile(loss='mae', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "wooden-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model\n",
    "def get_model(n_inputs, n_outputs):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(20, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    "\tmodel.add(Dense(n_outputs))\n",
    "\tmodel.compile(loss='mae', optimizer='adam')\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "warming-faculty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a model using repeated k-fold cross-validation\n",
    "def evaluate_model(X, y):\n",
    "\tresults = list()\n",
    "\tn_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    "\t# define evaluation procedure\n",
    "\tcv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\t# enumerate folds\n",
    "\tfor train_ix, test_ix in cv.split(X):\n",
    "\t\t# prepare data\n",
    "\t\tX_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "\t\ty_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "\t\t# define model\n",
    "\t\tmodel = get_model(n_inputs, n_outputs)\n",
    "\t\t# fit model\n",
    "\t\tmodel.fit(X_train, y_train, verbose=0, epochs=100)\n",
    "\t\t# evaluate model on test set\n",
    "\t\tmae = model.evaluate(X_test, y_test, verbose=0)\n",
    "\t\t# store result\n",
    "\t\tprint('>%.3f' % mae)\n",
    "\t\tresults.append(mae)\n",
    "\treturn results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-frequency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp for multi-output regression\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# evaluate model\n",
    "results = evaluate_model(X, y)\n",
    "# summarize performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(results), std(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-fellowship",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
